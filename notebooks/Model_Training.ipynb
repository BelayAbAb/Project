# Install necessary libraries if not already installed
# Uncomment the following line if you need to install seaborn
# !pip install seaborn

# Import libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (accuracy_score, precision_score, recall_score,
                             f1_score, confusion_matrix, classification_report)
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier

# Load your dataset
df = pd.read_csv('C:/Users/User/Desktop/10Acadamy/Week 8/Resource/Data/creditcard.csv')  # Update with the correct path

# Data Preparation
# Feature and target separation
X = df.drop(columns='Class')  # Replace 'Class' with the actual target variable name
y = df['Class']

# Train-test split (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Model Selection
# Define the models you want to evaluate
models = {
    'Logistic Regression': LogisticRegression(max_iter=1000),
    'Random Forest': RandomForestClassifier(random_state=42),
    'Support Vector Machine': SVC(),
    'Decision Tree': DecisionTreeClassifier(random_state=42)
}

# Initialize a list to store results
results = []

# Train each model and evaluate
for model_name, model in models.items():
    # Train the model
    model.fit(X_train, y_train)

    # Predictions on training data
    y_train_pred = model.predict(X_train)
    y_test_pred = model.predict(X_test)

    # Calculate metrics
    train_accuracy = accuracy_score(y_train, y_train_pred)
    test_accuracy = accuracy_score(y_test, y_test_pred)
   
    train_precision = precision_score(y_train, y_train_pred, average='weighted', zero_division=0)
    test_precision = precision_score(y_test, y_test_pred, average='weighted', zero_division=0)
   
    train_recall = recall_score(y_train, y_train_pred, average='weighted', zero_division=0)
    test_recall = recall_score(y_test, y_test_pred, average='weighted', zero_division=0)

    train_f1 = f1_score(y_train, y_train_pred, average='weighted', zero_division=0)
    test_f1 = f1_score(y_test, y_test_pred, average='weighted', zero_division=0)

    # Append results to the list
    results.append({
        'Model': model_name,
        'Train Accuracy': train_accuracy,
        'Test Accuracy': test_accuracy,
        'Train Precision': train_precision,
        'Test Precision': test_precision,
        'Train Recall': train_recall,
        'Test Recall': test_recall,
        'Train F1 Score': train_f1,
        'Test F1 Score': test_f1
    })

# Convert the list of results to a DataFrame
results_df = pd.DataFrame(results)

# Print the results DataFrame
print(results_df)

# Model Evaluation on Best Model (Optional)
# Evaluate the best model (e.g., Random Forest) on the test set
best_model = RandomForestClassifier(random_state=42)
best_model.fit(X_train, y_train)
y_test_pred_best = best_model.predict(X_test)

# Confusion matrix for the best model
conf_matrix = confusion_matrix(y_test, y_test_pred_best)
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False,
            xticklabels=['Normal (0)', 'Fraud (1)'],
            yticklabels=['Normal (0)', 'Fraud (1)'])
plt.title('Confusion Matrix for Random Forest')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.savefig('confusion_matrix_random_forest.jpg')  # Save the confusion matrix as JPG
plt.show()

# Classification report for the best model
class_report = classification_report(y_test, y_test_pred_best)
print("\nClassification Report for Random Forest:")
print(class_report)

# Save classification report as text
with open('classification_report_random_forest.txt', 'w') as f:
    f.write(class_report)

